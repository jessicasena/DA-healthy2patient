{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac584e6b-cbb7-4013-a30c-5f1d8a6d6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from time import time\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb20be51-e532-493c-bf39-71f5236a89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(sample):\n",
    "    mag_vector = []\n",
    "    for s in sample:\n",
    "        mag_vector.append(math.sqrt(sum([s[0]**2, s[1]**2, s[2]**2])))\n",
    "    return mag_vector\n",
    "\n",
    "def A(sample):\n",
    "    feat = []\n",
    "    for col in range(0,sample.shape[1]):\n",
    "        average = np.average(sample[:, col])\n",
    "        feat.append(average)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def SD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        std = np.std(sample[:, col])\n",
    "        feat.append(std)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def AAD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        data = sample[col,:]\n",
    "        add = np.mean(np.absolute(data - np.mean(data)))\n",
    "        feat.append(add)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def ARA(sample):\n",
    "    #Average Resultant Acceleration[1]:\n",
    "    # Average of the square roots of the sum of the values of each axis squared √(xi^2 + yi^2+ zi^2) over the ED\n",
    "    feat = []\n",
    "    sum_square = 0\n",
    "    sample = np.power(sample, 2)\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        sum_square = sum_square + sample[:, col]\n",
    "\n",
    "    sample = np.sqrt(sum_square)\n",
    "    average = np.average(sample)\n",
    "    feat.append(average)\n",
    "    return np.mean(feat)\n",
    "\n",
    "def COR(sample):\n",
    "    feat = []\n",
    "    for axis_i in range(0, sample.shape[1]):\n",
    "        for axis_j in range(axis_i+1, sample.shape[1]):\n",
    "            cor = np.corrcoef(sample[:, axis_i], sample[:, axis_j])\n",
    "            cor = 0 if np.isnan(cor) else cor[0][1]\n",
    "            feat.append(cor)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def mag_mean(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_mean = np.mean(mag)\n",
    "    return ft_mean\n",
    "\n",
    "def mag_std(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_std = np.std(mag)\n",
    "    return ft_std\n",
    "\n",
    "\n",
    "def feature_extraction(sample):\n",
    "    \"\"\"\n",
    "    Derive three activity intensity cues: mean and standard deviation of activity intensity,\n",
    "    and duration of immobility during assessment window to summarize the data.\n",
    "    # Average - A,\n",
    "    # Standard Deviation - SD,\n",
    "    # Average Absolute Difference - AAD,\n",
    "    # Average Resultant Acceleration - ARA(1),\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    mag = magnitude(sample)\n",
    "    features = np.mean(mag)\n",
    "    features = np.hstack((features, np.std(mag)))\n",
    "    features = np.hstack((features, A(sample)))\n",
    "    features = np.hstack((features, SD(sample)))\n",
    "    features = np.hstack((features, AAD(sample)))\n",
    "    features = np.hstack((features, ARA(sample)))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b529d354-7e5a-4b7f-acbb-2bfbc3d3270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heart_rate', 'heart_rate_class', 'temp', 'temp_class', 'lenght_of_stay', 'is_dead', 'pain_score', 'pain_score_class', 'sofa_score', 'sofa_score_class', 'map', 'map_class', 'braden_score', 'braden_score_class', 'spo2', 'spo2_class', 'cam', 'patient_id']\n"
     ]
    }
   ],
   "source": [
    "data_input_file = \"/home/jsenadesouza/DA-healthy2patient/results/outcomes/dataset/dataset_demographics_poi.npz\"\n",
    "tmp = np.load(data_input_file, allow_pickle=True)\n",
    "X = tmp[\"X\"]\n",
    "y = tmp['y']\n",
    "X_char = tmp['X_char']\n",
    "y_col_names = list(tmp['y_col_names'])\n",
    "print(y_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c3fdfe-61c9-4fbd-821b-ced9d7e1dce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features\n",
      "23.21 seconds passed.\n"
     ]
    }
   ],
   "source": [
    "X_trasp = np.transpose(np.squeeze(X), (0, 1, 2))\n",
    "print(\"Extracting Features\")\n",
    "start = time()\n",
    "with Pool(20) as p:\n",
    "        X_feat = p.map(feature_extraction, X_trasp)\n",
    "end = time()\n",
    "print(f\"{end-start:.4} seconds passed.\")\n",
    "\n",
    "X_feat = np.array(X_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55890fb5-1584-471a-9866-dafcdadb0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clinical_data(y, y_col_names, target_col_name):\n",
    "    regression_val = [0, 2, 6, 8, 10, 14, 16]\n",
    "    col_target = y_col_names.index(target_col_name)\n",
    "    col_target_reg = y_col_names.index(target_col_name.split(\"_class\")[0])\n",
    "\n",
    "    clin_var_idx = []\n",
    "    for idx in regression_val:\n",
    "        idx = int(idx)\n",
    "        if idx != col_target and idx != col_target_reg:\n",
    "            clin_var_idx.append(idx)\n",
    "\n",
    "    clin_var = y[:, clin_var_idx]\n",
    "\n",
    "    print(f'Target = {y_col_names[col_target]}')\n",
    "    print(\"\\nCLinical variables used:\\n\")\n",
    "    print(clin_var_idx)\n",
    "    for idx in clin_var_idx:\n",
    "        print(f\"{y_col_names[idx]}\")\n",
    "\n",
    "    return clin_var.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41888ea9-4833-4c4f-ac84-06b79ea1f8e9",
   "metadata": {},
   "source": [
    "Classify with SVM using demographics features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934482b9-6ca8-4368-8b4e-b5b534886c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target = pain_score_class\n",
      "\n",
      "CLinical variables used:\n",
      "\n",
      "[0, 2, 8, 10, 14, 16]\n",
      "heart_rate\n",
      "temp\n",
      "sofa_score\n",
      "map\n",
      "spo2\n",
      "cam\n",
      " acc = 0.5207692307692308\n",
      "f1 = 0.4348027252850935\n",
      "recall = 0.6930115745796025\n",
      " acc = 0.7338461538461538\n",
      "f1 = 0.5608039494446093\n",
      "recall = 0.7303778117492903\n",
      " acc = 0.6307692307692307\n",
      "f1 = 0.43751149315458704\n",
      "recall = 0.4795300387596899\n",
      " acc = 0.2776923076923077\n",
      "f1 = 0.23016817486098945\n",
      "recall = 0.24098491140642303\n",
      " acc = 0.2063125481139338\n",
      "f1 = 0.20344051716600736\n",
      "recall = 0.571843853820598\n",
      "accuracy: 47.39 ± 21.56\n",
      "recall: 54.31 ± 18.69\n",
      "f1-score: 37.33 ± 14.49\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score\n",
    "from scipy import stats as st\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "target_col_name = \"pain_score_class\"\n",
    "col_idx_target = y_col_names.index(target_col_name)\n",
    "y_target = y[:, col_idx_target]\n",
    "\n",
    "clin_data = get_clinical_data(y, y_col_names, target_col_name)\n",
    "POI = np.expand_dims(np.array(X_char)[:, -1], axis=1)\n",
    "X_data = np.concatenate([X_char], axis=1)\n",
    "cum_acc, cum_recall,cum_f1 = [], [], []\n",
    "for train_index, test_index in skf.split(X_data, y_target):\n",
    "    clf = svm.SVC(class_weight='balanced')\n",
    "    clf = clf.fit(X_data[train_index], y_target[train_index])\n",
    "    y_pred = clf.predict(X_data[test_index])\n",
    "    y_true = y_target[test_index]\n",
    "    cum_acc.append(accuracy_score(y_true, y_pred))\n",
    "    cum_f1.append(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "    cum_recall.append(recall_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "    print(f\" acc = {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"f1 = {f1_score(y_true, y_pred, average='macro')}\")\n",
    "    print(f'recall = {recall_score(y_true, y_pred, average=\"macro\", zero_division=0)}')\n",
    "    \n",
    "ci_mean = st.t.interval(0.9, len(cum_acc) - 1, loc=np.mean(cum_acc), scale=st.sem(cum_acc))\n",
    "ci_f1 = st.t.interval(0.9, len(cum_f1) -1, loc=np.mean(cum_f1), scale=st.sem(cum_f1))\n",
    "ci_recall = st.t.interval(0.9, len(cum_recall) -1, loc=np.mean(cum_recall), scale=st.sem(cum_recall))\n",
    "\n",
    "print('accuracy: {:.2f} ± {:.2f}'.format(np.mean(cum_acc) * 100, abs(np.mean(cum_acc) - ci_mean[0]) * 100))\n",
    "print('recall: {:.2f} ± {:.2f}'.format(np.mean(cum_recall) * 100, abs(np.mean(cum_recall) - ci_recall[0]) * 100))\n",
    "print('f1-score: {:.2f} ± {:.2f}'.format(np.mean(cum_f1) * 100, abs(np.mean(cum_f1) - ci_f1[0]) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b2d0f-c38f-4041-bc3f-fc7dac305001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use the following code snippets for the corresponding tasks-  \n",
    "\n",
    "#AUC- \n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pred_score = full_model.predict(x_test)  #Sometimes full_model.predict_proba(x_test) \n",
    "fpr, tpr, = roc_curve(y_test, pred_score[:,1])  #False positive Rate and True positive rate #if .predict() returns only one value use                                                                                                    #pred_score instead of pred_score[:, 1]\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#ROC curve \n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", prop={\"size\":14})\n",
    "plt.show()\n",
    "\n",
    "#Precision-Recall curve-   #if you need to visualize the Precision-Recall relationship. \n",
    "prec, rec, = precision_recall_curve(y_test, pred_score[:,1])  #same instruction as predscore above\n",
    "avg_prec = average_precision_score(y_test, pred_score[:,1])\n",
    "\n",
    "#PR curve \n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(rec, prec, color='darkorange',\n",
    "         lw=lw, label='Average Precision = %0.2f' % avg_prec)\n",
    "plt.plot([0, 1], [1, 0], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize=15)\n",
    "plt.ylabel('Precision', fontsize=15)\n",
    "plt.title('Precision Recall characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower left\", prop={\"size\":14})\n",
    "plt.show()\n",
    "\n",
    "#Finding best Threshold-  #this threshold finding might help you in improving the values of F1-Score, Sensitivity, Specificity, etc. slightly. \n",
    "def Find_Optimal_Cutoff(target, predicted):  #Youden index \n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------    \n",
    "    list type, with optimal cutoff value\n",
    "       \n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr))\n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold'])\n",
    "\n",
    "threshold = Find_Optimal_Cutoff(y_test, pred_score[:,1])  #same instruction as pred_score above\n",
    "print(threshold)\n",
    "\n",
    "y_pred_2 = list(map(lambda x: 1 if x > threshold else 0, pred_score[:,1]))  #same instruction as pred_score above. \n",
    "\n",
    "confusion_matrix(y_test, y_pred_2)\n",
    "\n",
    "#if this confusion matrix is better you can calculate all the metrics (e.g., Sensitivity, Specificity, F1-score, Precision and NPV)\n",
    "#based on y_pred_2. In that case you have to write in the paper that you tuned the threshold using Youden Index. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
