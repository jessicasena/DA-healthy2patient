{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816f39d7-56a4-4fe7-8549-e65083d956c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "import tsfel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f4204-a148-4c74-93bf-c65678f6fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(sample):\n",
    "    mag_vector = []\n",
    "    for s in sample:\n",
    "        mag_vector.append(math.sqrt(sum([s[0]**2, s[1]**2, s[2]**2])))\n",
    "    return mag_vector\n",
    "\n",
    "def A(sample):\n",
    "    feat = []\n",
    "    for col in range(0,sample.shape[0]):\n",
    "        average = np.average(sample[col,:])\n",
    "        feat.append(average)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def SD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[0]):\n",
    "        std = np.std(sample[col,:])\n",
    "        feat.append(std)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def AAD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[0]):\n",
    "        data = sample[col,:]\n",
    "        add = np.mean(np.absolute(data - np.mean(data)))\n",
    "        feat.append(add)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def ARA(sample):\n",
    "    #Average Resultant Acceleration[1]:\n",
    "    # Average of the square roots of the sum of the values of each axis squared âˆš(xi^2 + yi^2+ zi^2) over the ED\n",
    "    feat = []\n",
    "    sum_square = 0\n",
    "    sample = np.power(sample, 2)\n",
    "    for col in range(0, sample.shape[0]):\n",
    "        sum_square = sum_square + sample[col,:]\n",
    "\n",
    "    sample = np.sqrt(sum_square)\n",
    "    average = np.average(sample)\n",
    "    feat.append(average)\n",
    "    return np.mean(feat)\n",
    "\n",
    "def COR(sample):\n",
    "    feat = []\n",
    "    for axis_i in range(0, sample.shape[0]):\n",
    "        for axis_j in range(axis_i+1, sample.shape[0]):\n",
    "            cor = np.corrcoef(sample[axis_i, :], sample[axis_j, :])\n",
    "            cor = 0 if np.isnan(cor) else cor[0][1]\n",
    "            feat.append(cor)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "def TBP(sample):\n",
    "    from scipy import signal\n",
    "    feat = []\n",
    "    sum_of_time = 0\n",
    "    for col in range(0, sample.shape[0]):\n",
    "        data = sample[col, :]\n",
    "        peaks = signal.find_peaks_cwt(data, np.arange(1,4))\n",
    "\n",
    "        feat.append(peaks)\n",
    "\n",
    "    return feat\n",
    "\n",
    "def mag_mean(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_mean = np.mean(mag)\n",
    "    return ft_mean\n",
    "\n",
    "def mag_std(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_std = np.std(mag)\n",
    "    return ft_std\n",
    "\n",
    "\n",
    "def feature_extraction(X):\n",
    "    \"\"\"\n",
    "    Derive three activity intensity cues: mean and standard deviation of activity intensity,\n",
    "    and duration of immobility during assessment window to summarize the data.\n",
    "    # Average - A,\n",
    "    # Standard Deviation - SD,\n",
    "    # Average Absolute Difference - AAD,\n",
    "    # Average Resultant Acceleration - ARA(1),\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for sample in tqdm(X):\n",
    "        #mag = magnitude(sample)\n",
    "        #ft_mean = np.mean(mag)\n",
    "        #ft_std = np.std(mag)\n",
    "        features = A(sample)\n",
    "        #features = np.hstack((features, SD(sample)))\n",
    "        #features = np.hstack((features, AAD(sample)))\n",
    "        #features = np.hstack((features, ARA(sample)))\n",
    "        # calculate duration of immobility\n",
    "        #features.append([ft_mean, ft_std])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b160125e-9dff-41a9-be5c-27c8718991a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import resampy\n",
    "\n",
    "##predefined filter coefficients, as found by Jan Brond\n",
    "A_coeff = np.array(\n",
    "    [1, -4.1637, 7.5712,-7.9805, 5.385, -2.4636, 0.89238, 0.06361, -1.3481, 2.4734, -2.9257, 2.9298, -2.7816, 2.4777,\n",
    "     -1.6847, 0.46483, 0.46565, -0.67312, 0.4162, -0.13832, 0.019852])\n",
    "B_coeff = np.array(\n",
    "    [0.049109, -0.12284, 0.14356, -0.11269, 0.053804, -0.02023, 0.0063778, 0.018513, -0.038154, 0.048727, -0.052577,\n",
    "     0.047847, -0.046015, 0.036283, -0.012977, -0.0046262, 0.012835, -0.0093762, 0.0034485, -0.00080972, -0.00019623])\n",
    "\n",
    "def pptrunc(data, max_value):\n",
    "    '''\n",
    "    Saturate a vector such that no element's absolute value exceeds max_abs_value.\n",
    "    Current name: absolute_saturate().\n",
    "      :param data: a vector of any dimension containing numerical data\n",
    "      :param max_value: a float value of the absolute value to not exceed\n",
    "      :return: the saturated vector\n",
    "    '''\n",
    "    outd = np.where(data > max_value, max_value, data)\n",
    "    return np.where(outd < -max_value, -max_value, outd)\n",
    "\n",
    "def trunc(data, min_value):\n",
    "  \n",
    "    '''\n",
    "    Truncate a vector such that any value lower than min_value is set to 0.\n",
    "    Current name zero_truncate().\n",
    "    :param data: a vector of any dimension containing numerical data\n",
    "    :param min_value: a float value the elements of data should not fall below\n",
    "    :return: the truncated vector\n",
    "    '''\n",
    "\n",
    "    return np.where(data < min_value, 0, data)\n",
    "\n",
    "def runsum(data, length, threshold):\n",
    "    '''\n",
    "    Compute the running sum of values in a vector exceeding some threshold within a range of indices.\n",
    "    Divides the data into len(data)/length chunks and sums the values in excess of the threshold for each chunk.\n",
    "    Current name run_sum().\n",
    "    :param data: a 1D numerical vector to calculate the sum of\n",
    "    :param len: the length of each chunk to compute a sum along, as a positive integer\n",
    "    :param threshold: a numerical value used to find values exceeding some threshold\n",
    "    :return: a vector of length len(data)/length containing the excess value sum for each chunk of data\n",
    "    '''\n",
    "    \n",
    "    N = len(data)\n",
    "    cnt = int(math.ceil(N/length))\n",
    "\n",
    "    rs = np.zeros(cnt)\n",
    "\n",
    "    for n in range(cnt):\n",
    "        for p in range(length*n, length*(n+1)):\n",
    "            if p<N and data[p]>=threshold:\n",
    "                rs[n] = rs[n] + data[p] - threshold\n",
    "\n",
    "    return rs\n",
    "\n",
    "def counts(data, filesf, B=B_coeff, A=A_coeff):\n",
    "    '''\n",
    "    Get activity counts for a set of accelerometer observations.\n",
    "    First resamples the data frequency to 30Hz, then applies a Butterworth filter to the signal, then filters by the\n",
    "    coefficient matrices, saturates and truncates the result, and applies a running sum to get the final counts.\n",
    "    Current name get_actigraph_counts()\n",
    "    :param data: the vertical axis of accelerometer readings, as a vector\n",
    "    :param filesf: the number of observations per second in the file\n",
    "    :param a: coefficient matrix for filtering the signal, as found by Jan Brond\n",
    "    :param b: coefficient matrix for filtering the signal, as found by Jan Brond\n",
    "    :return: a vector containing the final counts\n",
    "    '''\n",
    "    \n",
    "    deadband = 0.068\n",
    "    sf = 30\n",
    "    peakThreshold = 2.13\n",
    "    adcResolution = 0.0164\n",
    "    integN = 10\n",
    "    gain = 0.965\n",
    "\n",
    "    #if filesf>sf:\n",
    "    data = resampy.resample(np.asarray(data), filesf, sf)\n",
    "\n",
    "    B2, A2 = signal.butter(4, np.array([0.01, 7])/(sf/2), btype='bandpass')\n",
    "    dataf = signal.filtfilt(B2, A2, data)\n",
    "\n",
    "    B = B * gain\n",
    "\n",
    "    #NB: no need for a loop here as we only have one axis in array\n",
    "    fx8up = signal.lfilter(B, A, dataf)\n",
    "\n",
    "    fx8 = pptrunc(fx8up[::3], peakThreshold) #downsampling is replaced by slicing with step parameter\n",
    "\n",
    "    return runsum(np.floor(trunc(np.abs(fx8), deadband)/adcResolution), integN, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f4499f-61e2-4be1-91d6-b632b44eb774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POI(sample):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of time spent immobile in a window\n",
    "    \"\"\"\n",
    "    def calc_mob_per_min(countx, county, countz):\n",
    "        mob_per_min = []\n",
    "        for i in range(0, len(countx), 60):\n",
    "            countx_1m = np.mean(countx[i:i+60])\n",
    "            county_1m = np.mean(county[i:i+60])\n",
    "            countz_1m = np.mean(countz[i:i+60])\n",
    "            mob_per_min.append(np.mean([countx_1m, county_1m, countz_1m]))\n",
    "        return mob_per_min\n",
    "\n",
    "    def percentagem_of_immobility(mob_per_min):\n",
    "        mob_per_min = np.asarray(mob_per_min)\n",
    "        inactivity_counts = (mob_per_min <= 4).sum() \n",
    "        return inactivity_counts/len(mob_per_min)\n",
    "\n",
    "    # calculate counts per axis\n",
    "    c1_1s = counts(sample[0], 10)\n",
    "    c2_1s = counts(sample[1], 10)\n",
    "    c3_1s = counts(sample[2], 10)\n",
    "    mob_per_min = calc_mob_per_min(c1_1s, c2_1s, c3_1s)\n",
    "    POI = percentagem_of_immobility(mob_per_min)\n",
    "    return POI\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c88f78b8-4089-466d-a8de-aa6ea4c8a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_corr_mean(clin_variable, y, feat):\n",
    "    \n",
    "    col_idx = y_col_names.index(clin_variable)\n",
    "    y_target = np.array(y[:, col_idx].astype(float))\n",
    "    corr, pvalue = spearmanr(feat, y_target)\n",
    "    return corr, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "917fd5d4-2b5e-47e2-99bb-6d43c95203a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6499, 18000, 3)\n"
     ]
    }
   ],
   "source": [
    "data_input_file = \"/home/jsenadesouza/DA-healthy2patient/results/outcomes/dataset/f10_t1800_outcomesscore_patientid_acc_30minmargin_measurednowcol_30min_10hz_filtered.npz\"\n",
    "\n",
    "tmp = np.load(data_input_file, allow_pickle=True)\n",
    "X = tmp['X']\n",
    "y = tmp['y']\n",
    "y_col_names = list(tmp['y_col_names'])\n",
    "X = np.transpose(np.squeeze(X), (0, 1, 2))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d0174d-8760-4f80-99e3-7132f9c7abed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features\n",
      "7.4 seconds passed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting Features\")\n",
    "start = time()\n",
    "with Pool(10) as p:\n",
    "        X_feat = p.map(ARA, X)\n",
    "end = time()\n",
    "print(f\"{end-start:.2} seconds passed.\")\n",
    "#X_feat = np.array(feature_extraction(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea881607-f0f2-4d88-87bf-ac6366f58191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "X_feat = []\n",
    "for sample in X:\n",
    "\n",
    "    sample_mag = np.array(magnitude(sample))\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=sample_mag, sr=10)\n",
    "    X_feat.append(np.mean(mfccs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8524ec5-4bb9-457b-8240-62e49c2d9f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9856a1dd-a309-4971-809c-e6d40a1de6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7fc065253490>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa.display\n",
    "print(mfccs.shape)\n",
    "librosa.display.specshow(mfccs, sr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "431ae281-4b7b-490f-bc76-d67928b50f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearmanr correlation\n",
      "-0.09 (0.000000)\n",
      "0.09 (0.000000)\n",
      "0.00 (0.844048)\n",
      "0.03 (0.037337)\n",
      "0.10 (0.000000)\n",
      "-0.02 (0.053942)\n",
      "-0.00 (0.900299)\n",
      "0.15 (0.000000)\n",
      "-0.10 (0.000000)\n",
      "-0.04 (0.004657)\n"
     ]
    }
   ],
   "source": [
    "print(f\"spearmanr correlation\")\n",
    "variables = np.array(y_col_names)[[0, 2, 4, 5, 6, 8, 10, 12, 14, 16]]\n",
    "for clin_variable in variables:\n",
    "    corr, pvalue = cal_corr_mean(clin_variable, y, X_feat)\n",
    "    print(f\"{corr:.2f} ({pvalue:.6f})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19626527-a3ad-411f-a1a9-72ee65192f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart_rate_class\n",
      "high: 30.73\n",
      "low: 3.55\n",
      "normal: 65.72\n",
      "temp_class\n",
      "high: 22.39\n",
      "low: 6.37\n",
      "normal: 71.24\n",
      "is_dead\n",
      "0: 81.37\n",
      "1: 18.63\n",
      "pain_score_class\n",
      "mild: 92.66\n",
      "severe: 7.34\n",
      "sofa_score_class\n",
      "low: 82.98\n",
      "moderate: 17.02\n",
      "map_class\n",
      "high: 8.19\n",
      "low: 43.61\n",
      "normal: 48.21\n",
      "braden_score_class\n",
      "high: 37.70\n",
      "mild: 62.30\n",
      "spo2_class\n",
      "low: 15.54\n",
      "normal: 84.46\n",
      "cam\n",
      "-1: 0.94\n",
      "0: 80.37\n",
      "1: 18.70\n"
     ]
    }
   ],
   "source": [
    "variables_class = np.array(y_col_names)[[1, 3, 5, 7, 9, 11, 13, 15, 16]]\n",
    "for clin_variable in variables_class:\n",
    "    \n",
    "    col_idx = y_col_names.index(clin_variable)\n",
    "    y_target = np.array(y[:, col_idx])\n",
    "    print(clin_variable)\n",
    "    names, counts = np.unique(y_target, return_counts=True)\n",
    "    total = np.sum(counts)\n",
    "    for i in range(len(names)):\n",
    "        print(f\"{names[i]}: {counts[i]/total*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f818cd6-3525-4c0a-a1e7-abfb9a8b436d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
