{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cb1402",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f171fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from time import time\n",
    "from multiprocessing import Pool\n",
    "#from imblearn.over_sampling import KMeansSMOTE, SMOTE\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import umap\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c05459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(sample):\n",
    "    mag_vector = []\n",
    "    for s in sample:\n",
    "        mag_vector.append(math.sqrt(sum([s[0]**2, s[1]**2, s[2]**2])))\n",
    "    return mag_vector\n",
    "\n",
    "def A(sample):\n",
    "    feat = []\n",
    "    for col in range(0,sample.shape[1]):\n",
    "        average = np.average(sample[:, col])\n",
    "        feat.append(average)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def SD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        std = np.std(sample[:, col])\n",
    "        feat.append(std)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def AAD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        data = sample[col,:]\n",
    "        add = np.mean(np.absolute(data - np.mean(data)))\n",
    "        feat.append(add)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def ARA(sample):\n",
    "    #Average Resultant Acceleration[1]:\n",
    "    # Average of the square roots of the sum of the values of each axis squared âˆš(xi^2 + yi^2+ zi^2) over the ED\n",
    "    feat = []\n",
    "    sum_square = 0\n",
    "    sample = np.power(sample, 2)\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        sum_square = sum_square + sample[:, col]\n",
    "\n",
    "    sample = np.sqrt(sum_square)\n",
    "    average = np.average(sample)\n",
    "    feat.append(average)\n",
    "    return np.mean(feat)\n",
    "\n",
    "def COR(sample):\n",
    "    feat = []\n",
    "    for axis_i in range(0, sample.shape[1]):\n",
    "        for axis_j in range(axis_i+1, sample.shape[1]):\n",
    "            cor = np.corrcoef(sample[:, axis_i], sample[:, axis_j])\n",
    "            cor = 0 if np.isnan(cor) else cor[0][1]\n",
    "            feat.append(cor)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def mag_mean(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_mean = np.mean(mag)\n",
    "    return ft_mean\n",
    "\n",
    "def mag_std(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_std = np.std(mag)\n",
    "    return ft_std\n",
    "\n",
    "\n",
    "def feature_extraction(sample):\n",
    "    \"\"\"\n",
    "    Derive three activity intensity cues: mean and standard deviation of activity intensity,\n",
    "    and duration of immobility during assessment window to summarize the data.\n",
    "    # Average - A,\n",
    "    # Standard Deviation - SD,\n",
    "    # Average Absolute Difference - AAD,\n",
    "    # Average Resultant Acceleration - ARA(1),\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    mag = magnitude(sample)\n",
    "    features = np.mean(mag)\n",
    "    features = np.hstack((features, np.std(mag)))\n",
    "    features = np.hstack((features, A(sample)))\n",
    "    features = np.hstack((features, SD(sample)))\n",
    "    features = np.hstack((features, AAD(sample)))\n",
    "    features = np.hstack((features, ARA(sample)))\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee0fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clinical_data(y):\n",
    "    regression_val = [0, 2, 4, 5, 6, 8, 10, 12, 14, 16]\n",
    "\n",
    "    clin_var = y[:, regression_val]\n",
    "\n",
    "    print(\"\\nClinical variables (regression) used:\\n\")\n",
    "    for idx in regression_val:\n",
    "        print(f\"{y_col_names[idx]}\")\n",
    "\n",
    "    return clin_var.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "788168bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_target(X, y, X_char, col_target):\n",
    "    if '-1' in np.unique(y[:, col_target]):\n",
    "        idxs = np.argwhere(np.array(y[:, col_target]) != '-1')\n",
    "        X = X[idxs]\n",
    "        y = y[idxs]\n",
    "        X_char = X_char[idxs]\n",
    "    return np.squeeze(X), np.squeeze(y), np.squeeze(X_char)\n",
    "\n",
    "def clean_clin_data(X, y, X_char):\n",
    "    idxs = []\n",
    "    for i in range(len(y)):\n",
    "        if '-1' not in y[i, :]:\n",
    "            idxs.append(i)\n",
    "    X = X[idxs]\n",
    "    y = y[idxs]\n",
    "    X_char = X_char[idxs]      \n",
    "    return np.squeeze(X), np.squeeze(y), np.squeeze(X_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854e12a-2cce-4921-b2b7-fe797d242178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='gist_rainbow'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct\n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "def plot_features(X, y, y_real, title, columns):\n",
    "    n_class = len(np.unique(y))\n",
    "    if X.shape[-1] > 3:\n",
    "        reducer = PCA(n_components=3)\n",
    "        #reducer = umap.UMAP(n_components=3)\n",
    "        principalComponents = reducer.fit_transform(X)\n",
    "        print(\"Dimisionality reduced by UMAP\")\n",
    "    else:\n",
    "        principalComponents = X\n",
    "    principalDf = pd.DataFrame(data=principalComponents,\n",
    "                               columns=['First Component', 'Second Component', 'Third Component'])\n",
    "\n",
    "    y_dt = pd.DataFrame(data=y, columns=['dataset'])\n",
    "\n",
    "    finalDf = pd.concat([principalDf, y_dt, y_real], axis=1)\n",
    "\n",
    "    hover_dict = {'First Component': False, 'Second Component':False, 'Third Component':False, 'dataset':True}\n",
    "    for col in y_real.columns:\n",
    "        hover_dict[col] = True\n",
    "\n",
    "    ######### 3D ##############\n",
    "#     fig = px.scatter_3d(finalDf, x='First Component', y='Second Component', z='Third Component',\n",
    "#               color='class', opacity=0.7, hover_data=hover_dict)\n",
    "    \n",
    "#     # tight layout\n",
    "#     fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "#     fig.show()\n",
    "\n",
    "    fig2 = px.scatter(finalDf, x='First Component', y='Second Component', title=title + \" (\" + 'dataset' + ')',\n",
    "                  color='dataset', opacity=0.7, hover_data=hover_dict, color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "\n",
    "    # tight layout\n",
    "    #fig2.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig2.show()\n",
    "    \n",
    "    ######### 2D ##############\n",
    "    for col in y_real.columns[columns]:\n",
    "        fig2 = px.scatter(finalDf, x='First Component', y='Second Component', title=title + \" (\" + col + ')',\n",
    "                  color=col, opacity=0.7, hover_data=hover_dict, color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "\n",
    "        # tight layout\n",
    "        #fig2.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "        fig2.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd300f84",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (79215489.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [32]\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.array(_data), np.array(_labels) = zip(*c)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "def plot_accel(X, y):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    data = X[indices]\n",
    "    labels = y[indices]\n",
    "    zero = np.where(labels == 'mild')[0][0]\n",
    "    one = np.where(labels == 'severe')[0][0]\n",
    "    sample1 = data[zero]\n",
    "    sample2 = data[one]\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(sample1[:, 0])\n",
    "    plt.plot(sample1[:, 1])\n",
    "    plt.plot(sample1[:, 2])\n",
    "    plt.title(labels[zero])\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(sample2[:, 0])\n",
    "    plt.plot(sample2[:, 0])\n",
    "    plt.plot(sample2[:, 0])\n",
    "    plt.title(labels[one])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6fc3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ce87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_file = \"/home/jsenadesouza/DA-healthy2patient/results/outcomes/dataset/t900_INTELLIGENT_PAIN_ADAPT_15min.npz\"\n",
    "tmp = np.load(data_input_file, allow_pickle=True)\n",
    "X = tmp[\"X\"]\n",
    "y = tmp['y']\n",
    "y_col_names = list(tmp['y_col_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15e2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(X, y, col_target):\n",
    "    if '-1' in np.unique(y[:, col_target]):\n",
    "        idxs = np.argwhere(np.array(y[:, col_target]) != '-1')\n",
    "        X = X[idxs]\n",
    "        y = y[idxs]\n",
    "    return np.squeeze(X), np.squeeze(y)\n",
    "\n",
    "col_idx_target = y_col_names.index(\"pain_score_class\")\n",
    "X, y = clean(X, y, col_idx_target)\n",
    "y_target = y[:, col_idx_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb4b8976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_target == 'mild')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5f3322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(array([], dtype=int64),)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_accel(X, y_target)\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mplot_accel\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(_labels))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mwhere(_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmild\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m zero \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmild\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m one \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msevere\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m sample1 \u001b[38;5;241m=\u001b[39m data[zero]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "plot_accel(X, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad060f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "spearman_xy = []\n",
    "spearman_yz = []\n",
    "spearman_zx = []\n",
    "for sample in np.squeeze(X):\n",
    "    spearman_xy.append(stats.spearmanr(sample[:, 0], sample[:, 1]).correlation)\n",
    "    spearman_yz.append(stats.spearmanr(sample[:, 1], sample[:, 2]).correlation)\n",
    "    spearman_zx.append(stats.spearmanr(sample[:, 2], sample[:, 0]).correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'spearman_xy = {np.nanmean(spearman_xy)}')\n",
    "print(f'spearman_yz = {np.nanmean(spearman_yz)}')\n",
    "print(f'spearman_zx = {np.nanmean(spearman_zx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ac64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_data = []\n",
    "new_y_target = []\n",
    "for xx, yy in zip(X, y):\n",
    "    if yy[7] == \"severe\":\n",
    "        new_X_data.append(xx)\n",
    "        new_y_target.append(yy)\n",
    "\n",
    "X = np.array(new_X_data)\n",
    "y = np.array(new_y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc8f73",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c641a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_trasp = np.transpose(np.squeeze(X), (0, 1, 2))\n",
    "print(\"Extracting Features\")\n",
    "start = time()\n",
    "with Pool(30) as p:\n",
    "        X_feat = p.map(magnitude, X_trasp)\n",
    "end = time()\n",
    "print(f\"{end-start:.4} seconds passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824b716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"clinical data columns\")\n",
    "for i, j in enumerate(y_col_names):\n",
    "    print(f'{i} : {j}')\n",
    "\n",
    "X_feat = np.array(X_feat)\n",
    "\n",
    "class_val = [1, 3,5, 7, 9, 11, 13, 15, 16, 17]\n",
    "\n",
    "y_df = pd.DataFrame(y[:, class_val], columns=np.array(y_col_names)[class_val])\n",
    "\n",
    "print(\"\\nClinical variables (categorized) used:\\n\")\n",
    "for idx in class_val:\n",
    "    print(f\"{y_col_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_feat\n",
    "print(X_data.shape)\n",
    "columns_size = X_data.shape[1]\n",
    "y_target = ['PAIN' if 'P' in x else 'ADAPT' if \"I\" in x else 'Intel_ICU' for x in y[:, -1]]\n",
    "print(np.array(y_target).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef336152",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from combat.pycombat import pycombat\n",
    "df_data = pd.DataFrame(X_feat.T)\n",
    "print(df_data.shape)\n",
    "print(np.array(y_target).shape)\n",
    "#X_data_batch = pycombat(df_data, y_target)\n",
    "\n",
    "#print(X_data.shape)\n",
    "#print(X_data_batch.T.shape)\n",
    "#plot_features(X_data_batch.T, y_target, y_df, \"accel data\", [0,1])\n",
    "plot_features(X_data, y_target, y_df, \"accel data\", [3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acceleration(sample):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    time = np.arange(0, len(sample))\n",
    "  # add every single subplot to the figure with a for loop\n",
    "    sns.lineplot(sample[:, 0], label='x', ax=ax)\n",
    "    sns.lineplot(sample[:, 1], label='y', ax=ax)\n",
    "    sns.lineplot(sample[:, 2], label='z', ax=ax)\n",
    "    #ax.title.set_text(label + '\\n' + str(v))\n",
    "    #ax.set_ylim(-0.5,0.5)\n",
    "    #ax.legend()\n",
    "    #plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e65e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acceleration(np.squeeze(X[600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_data_batch.T.shape)\n",
    "plot_features(X_data_batch.T, y_target, y_class, y_df, 'cam', \"clinical data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate([demo], axis=1)\n",
    "print(X_data.shape)\n",
    "plot_features(X_data, y_target,  y_class,\"Demographics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc76c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate([poi, np.ones(poi.shape)], axis=1)\n",
    "print(X_data.shape)\n",
    "plot_features(X_data, y_target, \"Percentage of Immobile time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a11998",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate([X_feat], axis=1)\n",
    "print(X_data.shape)\n",
    "plot_features(X_data, y_target, \"Accelerometer handcrafted features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate([X_feat, clin_data, X_char], axis=1)\n",
    "print(X_data.shape)\n",
    "plot_features(X_data, y_target, \"All features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c025677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
