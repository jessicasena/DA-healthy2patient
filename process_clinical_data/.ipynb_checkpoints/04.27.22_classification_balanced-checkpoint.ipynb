{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cb1402",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f171fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from time import time\n",
    "from multiprocessing import Pool\n",
    "#from imblearn.over_sampling import KMeansSMOTE, SMOTE\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c05459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(sample):\n",
    "    mag_vector = []\n",
    "    for s in sample:\n",
    "        mag_vector.append(math.sqrt(sum([s[0]**2, s[1]**2, s[2]**2])))\n",
    "    return mag_vector\n",
    "\n",
    "def A(sample):\n",
    "    feat = []\n",
    "    for col in range(0,sample.shape[1]):\n",
    "        average = np.average(sample[:, col])\n",
    "        feat.append(average)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def SD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        std = np.std(sample[:, col])\n",
    "        feat.append(std)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def AAD(sample):\n",
    "    feat = []\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        data = sample[col,:]\n",
    "        add = np.mean(np.absolute(data - np.mean(data)))\n",
    "        feat.append(add)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def ARA(sample):\n",
    "    #Average Resultant Acceleration[1]:\n",
    "    # Average of the square roots of the sum of the values of each axis squared âˆš(xi^2 + yi^2+ zi^2) over the ED\n",
    "    feat = []\n",
    "    sum_square = 0\n",
    "    sample = np.power(sample, 2)\n",
    "    for col in range(0, sample.shape[1]):\n",
    "        sum_square = sum_square + sample[:, col]\n",
    "\n",
    "    sample = np.sqrt(sum_square)\n",
    "    average = np.average(sample)\n",
    "    feat.append(average)\n",
    "    return np.mean(feat)\n",
    "\n",
    "def COR(sample):\n",
    "    feat = []\n",
    "    for axis_i in range(0, sample.shape[1]):\n",
    "        for axis_j in range(axis_i+1, sample.shape[1]):\n",
    "            cor = np.corrcoef(sample[:, axis_i], sample[:, axis_j])\n",
    "            cor = 0 if np.isnan(cor) else cor[0][1]\n",
    "            feat.append(cor)\n",
    "\n",
    "    return np.mean(feat)\n",
    "\n",
    "\n",
    "def mag_mean(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_mean = np.mean(mag)\n",
    "    return ft_mean\n",
    "\n",
    "def mag_std(sample):\n",
    "    mag = magnitude(sample)\n",
    "    ft_std = np.std(mag)\n",
    "    return ft_std\n",
    "\n",
    "\n",
    "def feature_extraction(sample):\n",
    "    \"\"\"\n",
    "    Derive three activity intensity cues: mean and standard deviation of activity intensity,\n",
    "    and duration of immobility during assessment window to summarize the data.\n",
    "    # Average - A,\n",
    "    # Standard Deviation - SD,\n",
    "    # Average Absolute Difference - AAD,\n",
    "    # Average Resultant Acceleration - ARA(1),\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    mag = magnitude(sample)\n",
    "    features = np.mean(mag)\n",
    "    features = np.hstack((features, np.std(mag)))\n",
    "    features = np.hstack((features, A(sample)))\n",
    "    features = np.hstack((features, SD(sample)))\n",
    "    features = np.hstack((features, AAD(sample)))\n",
    "    features = np.hstack((features, ARA(sample)))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee0fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clinical_data(y, y_col_names, target_col_name):\n",
    "    regression_val = [0, 2, 6, 8, 10, 14, 16]\n",
    "    col_target = y_col_names.index(target_col_name)\n",
    "    col_target_reg = y_col_names.index(target_col_name.split(\"_class\")[0])\n",
    "\n",
    "    clin_var_idx = []\n",
    "    for idx in regression_val:\n",
    "        idx = int(idx)\n",
    "        if idx != col_target and idx != col_target_reg:\n",
    "            clin_var_idx.append(idx)\n",
    "\n",
    "    clin_var = y[:, clin_var_idx]\n",
    "\n",
    "    print(f'Target = {y_col_names[col_target]}')\n",
    "    print(\"\\nCLinical variables used:\\n\")\n",
    "    print(clin_var_idx)\n",
    "    for idx in clin_var_idx:\n",
    "        print(f\"{y_col_names[idx]}\")\n",
    "\n",
    "    return clin_var.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6fc3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data and balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ce87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_file = \"/home/jsenadesouza/DA-healthy2patient/results/outcomes/dataset/dataset_IntelligentICU_PAIN_Xchar_poi.npz\"\n",
    "tmp = np.load(data_input_file, allow_pickle=True)\n",
    "X = tmp[\"X\"]\n",
    "y = tmp['y']\n",
    "X_char = tmp['X_char']\n",
    "y_col_names = list(tmp['y_col_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a054ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7865, 1, 18000, 3)\n",
      "(7865, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_char.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788168bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(X, y, X_char, col_target):\n",
    "    if '-1' in np.unique(y[:, col_target]):\n",
    "        idxs = np.argwhere(np.array(y[:, col_target]) != '-1')\n",
    "        X = X[idxs]\n",
    "        y = y[idxs]\n",
    "        X_char = X_char[idxs]\n",
    "    return np.squeeze(X), np.squeeze(y), np.squeeze(X_char)\n",
    "\n",
    "def clean_clin_data(X, y, X_char):\n",
    "    idxs = []\n",
    "    for i in range(len(y)):\n",
    "        if '-1' not in y[i, :]:\n",
    "            idxs.append(i)\n",
    "    X = X[idxs]\n",
    "    y = y[idxs]\n",
    "    X_char = X_char[idxs]      \n",
    "    return np.squeeze(X), np.squeeze(y), np.squeeze(X_char)\n",
    "\n",
    "target_col_name = \"pain_score_class\"\n",
    "col_idx_target = y_col_names.index(target_col_name)\n",
    "X, y, X_char = clean(X, y, X_char, col_idx_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177fee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = np.array(y[:, col_idx_target])\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_target)\n",
    "y_target = le.transform(y_target)\n",
    "\n",
    "\n",
    "# y_target = np.array(y[:, col_idx_target]).astype(float)\n",
    "\n",
    "# y_categorized = []\n",
    "# for score in y_target:\n",
    "#     if score < 1:\n",
    "#         category = \"nopain\"\n",
    "#     elif 1 <= score < 5:\n",
    "#         category = \"mild\"\n",
    "#     elif 5 <= score < 7:\n",
    "#         category = \"moderate\"\n",
    "#     elif score > 6:\n",
    "#         category = \"high\"\n",
    "#     else:\n",
    "#         print(f\"Error : {score}\")\n",
    "#     y_categorized.append(category)\n",
    "    \n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(y_categorized)\n",
    "# y_target = le.transform(y_categorized)\n",
    "\n",
    "# print(y_col_names)\n",
    "# print(f'X shape{X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187b83e1-b6ab-4912-a524-5682e864fdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7865, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['X_char'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621a5fbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_categorized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_categorized, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_target, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(np.unique(y_categorized, return_counts=True))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_categorized' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_categorized, return_counts=True))\n",
    "print(np.unique(y_target, return_counts=True))\n",
    "#print(np.unique(y_categorized, return_counts=True))\n",
    "classes, counts = np.unique(y_categorized, return_counts=True)\n",
    "for cs, ct in zip(classes, counts):\n",
    "    print(f\"{cs}= {ct/len(y_categorized) *100:.2f}\")\n",
    "print(POI.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc8f73",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "203c641a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features\n",
      "47.82 seconds passed.\n"
     ]
    }
   ],
   "source": [
    "X_trasp = np.transpose(np.squeeze(X), (0, 1, 2))\n",
    "print(\"Extracting Features\")\n",
    "start = time()\n",
    "with Pool(20) as p:\n",
    "        X_feat = p.map(feature_extraction, X_trasp)\n",
    "end = time()\n",
    "print(f\"{end-start:.4} seconds passed.\")\n",
    "\n",
    "X_feat = np.array(X_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c074d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target = pain_score_class\n",
      "\n",
      "CLinical variables used:\n",
      "\n",
      "[0, 2, 8, 10, 14, 16]\n",
      "heart_rate\n",
      "temp\n",
      "sofa_score\n",
      "map\n",
      "spo2\n",
      "cam\n",
      "(7865, 6)\n"
     ]
    }
   ],
   "source": [
    "clin_data = get_clinical_data(y, y_col_names, target_col_name)\n",
    "poi = np.expand_dims(np.array(X_char)[:, -1], axis=1)\n",
    "demo = np.array(X_char)[:, 0:6]\n",
    "X_data = np.concatenate([clin_data], axis=1)\n",
    "print(X_data.shape)\n",
    "\n",
    "# from combat.pycombat import pycombat\n",
    "# X_data = np.transpose(X_data)\n",
    "\n",
    "# df_data = pd.DataFrame(X_data)\n",
    "\n",
    "# y_dataset = ['PAIN' if 'P' in x else 'Intel_ICU' for x in y[:, -1]]\n",
    "# X_data_batch = pycombat(df_data, y_dataset)\n",
    "# print(X_data_batch.T.shape)\n",
    "\n",
    "# X_data = X_data_batch.T.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d739e877-cfca-4303-815a-10b776d6f112",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification with XGboost class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85cc8329-e58e-44af-94d2-413b7b1afbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 8.419161676646707. Counter({0: 7030, 1: 835})\n",
      "train: (array([0, 1]), array([5624,  668]))\n",
      "test: (array([0, 1]), array([1406,  167]))\n",
      " acc = 0.7705022250476796\n",
      "f1 = [0.86848816 0.09975062]\n",
      "recall = [0.84779516 0.11976048]\n",
      "Precision = [0.89021658 0.08547009]\n",
      "train: (array([0, 1]), array([5624,  668]))\n",
      "test: (array([0, 1]), array([1406,  167]))\n",
      " acc = 0.8944691671964399\n",
      "f1 = [0.94384303 0.12631579]\n",
      "recall = [0.99217639 0.07185629]\n",
      "Precision = [0.9        0.52173913]\n",
      "train: (array([0, 1]), array([5624,  668]))\n",
      "test: (array([0, 1]), array([1406,  167]))\n",
      " acc = 0.8556897647806738\n",
      "f1 = [0.92115318 0.14981273]\n",
      "recall = [0.943101   0.11976048]\n",
      "Precision = [0.90020367 0.2       ]\n",
      "train: (array([0, 1]), array([5624,  668]))\n",
      "test: (array([0, 1]), array([1406,  167]))\n",
      " acc = 0.8506039415130324\n",
      "f1 = [0.9184311  0.11320755]\n",
      "recall = [0.94096728 0.08982036]\n",
      "Precision = [0.89694915 0.15306122]\n",
      "train: (array([0, 1]), array([5624,  668]))\n",
      "test: (array([0, 1]), array([1406,  167]))\n",
      " acc = 0.3521932612841704\n",
      "f1 = [0.43167875 0.24685883]\n",
      "recall = [0.27524893 1.        ]\n",
      "Precision = [1.         0.14080944]\n",
      "Class: 0\n",
      "accuracy: 74.47 Â± 27.81\n",
      "recall: 79.99 Â± 36.99\n",
      "f1-score: 81.67 Â± 26.94\n",
      "precision: 91.75 Â± 5.75\n",
      "Class: 1\n",
      "accuracy: 74.47 Â± 27.81\n",
      "recall: 28.02 Â± 50.02\n",
      "f1-score: 14.72 Â± 7.29\n",
      "precision: 22.02 Â± 21.53\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score, precision_score\n",
    "from scipy import stats as st\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from collections import Counter\n",
    "\n",
    "average_param = None\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "counter = Counter(y_target)\n",
    "# estimate scale_pos_weight value\n",
    "estimate = counter[0] / counter[1]\n",
    "print(f'Estimate: {estimate}. {counter}')\n",
    "\n",
    "\n",
    "cum_acc, cum_recall, cum_f1, cum_auc, cum_AUROC, cum_prec = [], [], [], [], [], []\n",
    "actual_y, predicted_y = [], []\n",
    "for train_index, test_index in skf.split(X_data, y_target):\n",
    "    X_train, y_train = X_data[train_index], y_target[train_index]\n",
    "    X_test, y_test = X_data[test_index], y_target[test_index]\n",
    "        \n",
    "    print(f'train: {np.unique(y_train, return_counts=True)}')\n",
    "    print(f'test: {np.unique(y_test, return_counts=True)}')\n",
    "    #print(y_train)\n",
    "          \n",
    "\n",
    "    # fit model no training data\n",
    "    model = XGBClassifier(tree_method=\"gpu_hist\",use_label_encoder=False, eval_metric='logloss', scale_pos_weight=estimate)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [round(value) for value in y_pred]\n",
    "    y_true = y_test\n",
    "    actual_y.extend(y_true)\n",
    "    predicted_y.extend(y_pred)\n",
    "    cum_acc.append(accuracy_score(y_true, y_pred))\n",
    "    cum_f1.append(f1_score(y_true, y_pred, average=average_param))\n",
    "    cum_recall.append(recall_score(y_true, y_pred, average=average_param))\n",
    "    print(f\" acc = {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"f1 = {f1_score(y_true, y_pred, average=average_param)}\")\n",
    "    print(f'recall = {recall_score(y_true, y_pred, average=average_param)}')\n",
    "    precision = precision_score(y_true, y_pred, average=average_param)\n",
    "    cum_prec.append(precision)\n",
    "    print(f'Precision = {precision}')\n",
    "    \n",
    "    # fpr, tpr, _ = roc_curve(y_true, y_pred)  #False positive Rate and True positive rate #if .predict() returns only one value use                                                                                                    #pred_score instead of pred_score[:, 1]\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "    # print(f'AUC= {roc_auc}')\n",
    "    # AUROC = roc_auc_score(y_true, y_pred)\n",
    "    # print(f'AUROC= {AUROC}')\n",
    "    # cum_auc.append(roc_auc)\n",
    "    # cum_AUROC.append(AUROC)\n",
    "    \n",
    "    \n",
    "for class_ in range(len(np.unique(y_target))):\n",
    "    print(f\"Class: {class_}\")\n",
    "    current_acc = np.array(cum_acc)\n",
    "    current_f1 = np.array(cum_f1)[:, class_]\n",
    "    current_recall = np.array(cum_recall)[:, class_]\n",
    "    current_prec = np.array(cum_prec)[:, class_]\n",
    "    ci_mean = st.t.interval(0.95, len(current_acc) - 1, loc=np.mean(current_acc), scale=st.sem(current_acc))\n",
    "    ci_f1 = st.t.interval(0.95, len(current_f1) -1, loc=np.mean(current_f1), scale=st.sem(current_f1))\n",
    "    ci_recall = st.t.interval(0.95, len(current_recall) -1, loc=np.mean(current_recall), scale=st.sem(current_recall))\n",
    "    #ci_auc = st.t.interval(0.95, len(cum_auc) -1, loc=np.mean(cum_auc), scale=st.sem(cum_auc))\n",
    "    # ci_AUROC = st.t.interval(0.95, len(cum_AUROC) -1, loc=np.mean(cum_AUROC), scale=st.sem(cum_AUROC))\n",
    "    ci_prec = st.t.interval(0.95, len(current_prec) -1, loc=np.mean(current_prec), scale=st.sem(current_prec))\n",
    "\n",
    "    print('accuracy: {:.2f} Â± {:.2f}'.format(np.mean(current_acc) * 100, abs(np.mean(current_acc) - ci_mean[0]) * 100))\n",
    "    print('recall: {:.2f} Â± {:.2f}'.format(np.mean(current_recall) * 100, abs(np.mean(current_recall) - ci_recall[0]) * 100))\n",
    "    print('f1-score: {:.2f} Â± {:.2f}'.format(np.mean(current_f1) * 100, abs(np.mean(current_f1) - ci_f1[0]) * 100))\n",
    "    print('precision: {:.2f} Â± {:.2f}'.format(np.mean(current_prec) * 100, abs(np.mean(current_prec) - ci_prec[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08eaeb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10616656071201525\n"
     ]
    }
   ],
   "source": [
    "np.unique(y_target, return_counts=True)\n",
    "print(1- (7030 / (7030 + 835)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abaf26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Classify with SVM Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score, precision_score\n",
    "from scipy import stats as st\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "cum_acc, cum_recall, cum_f1, cum_auc, cum_prec = [], [], [], [], []\n",
    "actual_y, predicted_y = [], []\n",
    "for train_index, test_index in skf.split(X_data, y_target):\n",
    "    X_train, y_train = X_data[train_index], y_target[train_index]\n",
    "    X_test, y_test = X_data[test_index], y_target[test_index]\n",
    "    \n",
    "    # paper: Oversampling for imbalanced learning based on k-means and SMOTE\n",
    "    try:\n",
    "        sm = KMeansSMOTE(random_state=42, k_neighbors=10, kmeans_estimator=100)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        print(\"Using KmeansSMOTE\")\n",
    "    except:\n",
    "        sm = SMOTE(random_state=42, k_neighbors=10)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        print(\"Using SMOTE\")\n",
    "    print(f'train: {np.unique(y_train, return_counts=True)}')\n",
    "    print(f'test: {np.unique(y_test, return_counts=True)}')\n",
    "          \n",
    "    #clf = svm.SVC(class_weight='balanced')\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_true = y_test\n",
    "    cum_acc.append(accuracy_score(y_true, y_pred))\n",
    "    cum_f1.append(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "    cum_recall.append(recall_score(y_true, y_pred, average=\"macro\"))\n",
    "    print(f\" acc = {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"f1 = {f1_score(y_true, y_pred, average='macro')}\")\n",
    "    print(f'recall = {recall_score(y_true, y_pred, average=\"macro\")}')\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)  #False positive Rate and True positive rate #if .predict() returns only one value use                                                                                                    #pred_score instead of pred_score[:, 1]\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC= {roc_auc}')\n",
    "    cum_auc.append(roc_auc)\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    cum_prec.append(precision)\n",
    "    print(f'Precision = {precision}')\n",
    "    actual_y.extend(y_true)\n",
    "    predicted_y.extend(y_pred)\n",
    "    \n",
    "ci_mean = st.t.interval(0.95, len(cum_acc) - 1, loc=np.mean(cum_acc), scale=st.sem(cum_acc))\n",
    "ci_f1 = st.t.interval(0.95, len(cum_f1) -1, loc=np.mean(cum_f1), scale=st.sem(cum_f1))\n",
    "ci_recall = st.t.interval(0.95, len(cum_recall) -1, loc=np.mean(cum_recall), scale=st.sem(cum_recall))\n",
    "ci_prec = st.t.interval(0.95, len(cum_prec) -1, loc=np.mean(cum_prec), scale=st.sem(cum_prec))\n",
    "\n",
    "# ci_auc = st.t.interval(0.95, len(cum_auc) -1, loc=np.mean(cum_auc), scale=st.sem(cum_auc))\n",
    "\n",
    "print('accuracy: {:.2f} Â± {:.2f}'.format(np.mean(cum_acc) * 100, abs(np.mean(cum_acc) - ci_mean[0]) * 100))\n",
    "print('recall: {:.2f} Â± {:.2f}'.format(np.mean(cum_recall) * 100, abs(np.mean(cum_recall) - ci_recall[0]) * 100))\n",
    "print('f1-score: {:.2f} Â± {:.2f}'.format(np.mean(cum_f1) * 100, abs(np.mean(cum_f1) - ci_f1[0]) * 100))\n",
    "print('precision: {:.2f} Â± {:.2f}'.format(np.mean(cum_prec) * 100, abs(np.mean(cum_prec) - ci_prec[0]) * 100))\n",
    "#print('auc: {:.2f} Â± {:.2f}'.format(np.mean(cum_auc) * 100, abs(np.mean(cum_auc) - ci_auc[0]) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07732d0b-f873-47a5-972b-4dc33dfa6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(actual_y, predicted_y, ['mild', 'severe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc269d7-9080-4850-84ee-e71f505cd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(actual_classes : np.array, predicted_classes : np.array, sorted_labels : list):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes)\n",
    "    \n",
    "    matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af7818",
   "metadata": {},
   "source": [
    "## Classification with XGboost Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score, precision_score\n",
    "from scipy import stats as st\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "average_param = None\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "cum_acc, cum_recall, cum_f1, cum_auc, cum_AUROC, cum_prec = [], [], [], [], [], []\n",
    "actual_y, predicted_y = [], []\n",
    "for train_index, test_index in skf.split(X_data, y_target):\n",
    "    X_train, y_train = X_data[train_index], y_target[train_index]\n",
    "    X_test, y_test = X_data[test_index], y_target[test_index]\n",
    "    \n",
    "    # paper: Oversampling for imbalanced learning based on k-means and SMOTE\n",
    "    try:\n",
    "        sm = KMeansSMOTE(random_state=42, k_neighbors=10, kmeans_estimator=100)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        print(\"Using KmeansSMOTE\")\n",
    "    except:\n",
    "        sm = SMOTE(random_state=42, k_neighbors=10)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        print(\"Using SMOTE\")\n",
    "        \n",
    "    print(f'train: {np.unique(y_train, return_counts=True)}')\n",
    "    print(f'test: {np.unique(y_test, return_counts=True)}')\n",
    "    #print(y_train)\n",
    "          \n",
    "\n",
    "    # fit model no training data\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [round(value) for value in y_pred]\n",
    "    y_true = y_test\n",
    "    actual_y.extend(y_true)\n",
    "    predicted_y.extend(y_pred)\n",
    "    cum_acc.append(accuracy_score(y_true, y_pred))\n",
    "    cum_f1.append(f1_score(y_true, y_pred, average=average_param))\n",
    "    cum_recall.append(recall_score(y_true, y_pred, average=average_param))\n",
    "    print(f\" acc = {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"f1 = {f1_score(y_true, y_pred, average=average_param)}\")\n",
    "    print(f'recall = {recall_score(y_true, y_pred, average=average_param)}')\n",
    "    precision = precision_score(y_true, y_pred, average=average_param)\n",
    "    cum_prec.append(precision)\n",
    "    print(f'Precision = {precision}')\n",
    "    \n",
    "    # fpr, tpr, _ = roc_curve(y_true, y_pred)  #False positive Rate and True positive rate #if .predict() returns only one value use                                                                                                    #pred_score instead of pred_score[:, 1]\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "    # print(f'AUC= {roc_auc}')\n",
    "    # AUROC = roc_auc_score(y_true, y_pred)\n",
    "    # print(f'AUROC= {AUROC}')\n",
    "    # cum_auc.append(roc_auc)\n",
    "    # cum_AUROC.append(AUROC)\n",
    "    \n",
    "    \n",
    "for class_ in range(len(np.unique(y_target))):\n",
    "    print(f\"Class: {class_}\")\n",
    "    current_acc = np.array(cum_acc)\n",
    "    current_f1 = np.array(cum_f1)[:, class_]\n",
    "    current_recall = np.array(cum_recall)[:, class_]\n",
    "    current_prec = np.array(cum_prec)[:, class_]\n",
    "    ci_mean = st.t.interval(0.95, len(current_acc) - 1, loc=np.mean(current_acc), scale=st.sem(current_acc))\n",
    "    ci_f1 = st.t.interval(0.95, len(current_f1) -1, loc=np.mean(current_f1), scale=st.sem(current_f1))\n",
    "    ci_recall = st.t.interval(0.95, len(current_recall) -1, loc=np.mean(current_recall), scale=st.sem(current_recall))\n",
    "    #ci_auc = st.t.interval(0.95, len(cum_auc) -1, loc=np.mean(cum_auc), scale=st.sem(cum_auc))\n",
    "    # ci_AUROC = st.t.interval(0.95, len(cum_AUROC) -1, loc=np.mean(cum_AUROC), scale=st.sem(cum_AUROC))\n",
    "    ci_prec = st.t.interval(0.95, len(current_prec) -1, loc=np.mean(current_prec), scale=st.sem(current_prec))\n",
    "\n",
    "    print('accuracy: {:.2f} Â± {:.2f}'.format(np.mean(current_acc) * 100, abs(np.mean(current_acc) - ci_mean[0]) * 100))\n",
    "    print('recall: {:.2f} Â± {:.2f}'.format(np.mean(current_recall) * 100, abs(np.mean(current_recall) - ci_recall[0]) * 100))\n",
    "    print('f1-score: {:.2f} Â± {:.2f}'.format(np.mean(current_f1) * 100, abs(np.mean(current_f1) - ci_f1[0]) * 100))\n",
    "    print('precision: {:.2f} Â± {:.2f}'.format(np.mean(current_prec) * 100, abs(np.mean(current_prec) - ci_prec[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7833e-478a-4f21-9fa1-63639a1f8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe852a9d-f990-44db-b32f-9523d976711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81389ce-5829-4350-8848-55e0f0fb30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(actual_y, predicted_y, ['high', 'mild', 'moderate', 'nopain'])\n",
    "plot_confusion_matrix(actual_y, predicted_y, ['mild', 'severe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09914e90-9450-48e5-811a-38a16ab426f8",
   "metadata": {},
   "source": [
    "## Classification with XGboost undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ef459-27e9-4443-9a49-8a2f585fa922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score\n",
    "from scipy import stats as st\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "average_param = 'weighted'\n",
    "cum_acc, cum_recall, cum_f1, cum_auc, cum_AUROC, cum_pred = [], [], [], [], [], []\n",
    "actual_y, predicted_y = [], []\n",
    "for train_index, test_index in skf.split(X_data, y_target):\n",
    "    X_train, y_train = X_data[train_index], y_target[train_index]\n",
    "    X_test, y_test = X_data[test_index], y_target[test_index]\n",
    "    \n",
    "\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "        \n",
    "    print(f'train: {np.unique(y_train, return_counts=True)}')\n",
    "    print(f'test: {np.unique(y_test, return_counts=True)}')\n",
    "    #print(y_train)\n",
    "          \n",
    "\n",
    "    # fit model no training data\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [round(value) for value in y_pred]\n",
    "    y_true = y_test\n",
    "    actual_y.extend(y_true)\n",
    "    predicted_y.extend(y_pred)\n",
    "    cum_acc.append(accuracy_score(y_true, y_pred))\n",
    "    cum_f1.append(f1_score(y_true, y_pred, average= average_param))\n",
    "    cum_recall.append(recall_score(y_true, y_pred, average=average_param))\n",
    "    print(f\" acc = {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"f1 = {f1_score(y_true, y_pred, average=average_param)}\")\n",
    "    print(f'recall = {recall_score(y_true, y_pred, average=average_param)}')\n",
    "    # fpr, tpr, _ = roc_curve(y_true, y_pred)  #False positive Rate and True positive rate #if .predict() returns only one value use                                                                                                    #pred_score instead of pred_score[:, 1]\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "    # print(f'AUC= {roc_auc}')\n",
    "    # AUROC = roc_auc_score(y_true, y_pred)\n",
    "    # print(f'AUROC= {AUROC}')\n",
    "    # cum_auc.append(roc_auc)\n",
    "    # cum_AUROC.append(AUROC)\n",
    "    precision = precision_score(y_true, y_pred, average=average_param)\n",
    "    cum_prec.append(precision)\n",
    "    print(f'Precision = {precision}')\n",
    "    \n",
    "ci_mean = st.t.interval(0.95, len(cum_acc) - 1, loc=np.mean(cum_acc), scale=st.sem(cum_acc))\n",
    "ci_f1 = st.t.interval(0.95, len(cum_f1) -1, loc=np.mean(cum_f1), scale=st.sem(cum_f1))\n",
    "ci_recall = st.t.interval(0.95, len(cum_recall) -1, loc=np.mean(cum_recall), scale=st.sem(cum_recall))\n",
    "ci_auc = st.t.interval(0.95, len(cum_auc) -1, loc=np.mean(cum_auc), scale=st.sem(cum_auc))\n",
    "# ci_AUROC = st.t.interval(0.95, len(cum_AUROC) -1, loc=np.mean(cum_AUROC), scale=st.sem(cum_AUROC))\n",
    "ci_prec = st.t.interval(0.95, len(cum_prec) -1, loc=np.mean(cum_prec), scale=st.sem(cum_prec))\n",
    "\n",
    "print('accuracy: {:.2f} Â± {:.2f}'.format(np.mean(cum_acc) * 100, abs(np.mean(cum_acc) - ci_mean[0]) * 100))\n",
    "print('recall: {:.2f} Â± {:.2f}'.format(np.mean(cum_recall) * 100, abs(np.mean(cum_recall) - ci_recall[0]) * 100))\n",
    "print('f1-score: {:.2f} Â± {:.2f}'.format(np.mean(cum_f1) * 100, abs(np.mean(cum_f1) - ci_f1[0]) * 100))\n",
    "print('precision: {:.2f} Â± {:.2f}'.format(np.mean(cum_prec) * 100, abs(np.mean(cum_prec) - ci_prec[0]) * 100))\n",
    "#print('auc: {:.2f} Â± {:.2f}'.format(np.mean(cum_auc) * 100, abs(np.mean(cum_auc) - ci_auc[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99706d-d937-4851-b3c0-1feaa9dba007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(actual_y, predicted_y, ['high', 'mild', 'moderate', 'nopain'])\n",
    "plot_confusion_matrix(actual_y, predicted_y, ['mild', 'severe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991635b-124a-40fa-82e4-c112c3842767",
   "metadata": {},
   "source": [
    "## Classification with XGboost undersampling and upsampling combination : SMOTETomek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787e926-e23c-4a26-b018-ed0451067604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score\n",
    "from scipy import stats as st\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "cum_acc, cum_recall, cum_f1, cum_auc, cum_AUROC, cum_pred = [], [], [], [], [], []\n",
    "actual_y, predicted_y = [], []\n",
    "for train_index, test_index in skf.split(X_data, y_target):\n",
    "    X_train, y_train = X_data[train_index], y_target[train_index]\n",
    "    X_test, y_test = X_data[test_index], y_target[test_index]\n",
    "    \n",
    "\n",
    "    rus = SMOTETomek(random_state=42)\n",
    "    X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "        \n",
    "    print(f'train: {np.unique(y_train, return_counts=True)}')\n",
    "    print(f'test: {np.unique(y_test, return_counts=True)}')\n",
    "    #print(y_train)\n",
    "          \n",
    "\n",
    "    # fit model no training data\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [round(value) for value in y_pred]\n",
    "    y_true = y_test\n",
    "    actual_y.extend(y_true)\n",
    "    predicted_y.extend(y_pred)\n",
    "    cum_acc.append(accuracy_score(y_true, y_pred))\n",
    "    cum_f1.append(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "    cum_recall.append(recall_score(y_true, y_pred, average=\"macro\"))\n",
    "    print(f\" acc = {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"f1 = {f1_score(y_true, y_pred, average='macro')}\")\n",
    "    print(f'recall = {recall_score(y_true, y_pred, average=\"macro\")}')\n",
    "    # fpr, tpr, _ = roc_curve(y_true, y_pred)  #False positive Rate and True positive rate #if .predict() returns only one value use                                                                                                    #pred_score instead of pred_score[:, 1]\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "    # print(f'AUC= {roc_auc}')\n",
    "    # AUROC = roc_auc_score(y_true, y_pred)\n",
    "    # print(f'AUROC= {AUROC}')\n",
    "    # cum_auc.append(roc_auc)\n",
    "    # cum_AUROC.append(AUROC)\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    cum_prec.append(precision)\n",
    "    print(f'Precision = {precision}')\n",
    "    \n",
    "ci_mean = st.t.interval(0.95, len(cum_acc) - 1, loc=np.mean(cum_acc), scale=st.sem(cum_acc))\n",
    "ci_f1 = st.t.interval(0.95, len(cum_f1) -1, loc=np.mean(cum_f1), scale=st.sem(cum_f1))\n",
    "ci_recall = st.t.interval(0.95, len(cum_recall) -1, loc=np.mean(cum_recall), scale=st.sem(cum_recall))\n",
    "ci_auc = st.t.interval(0.95, len(cum_auc) -1, loc=np.mean(cum_auc), scale=st.sem(cum_auc))\n",
    "# ci_AUROC = st.t.interval(0.95, len(cum_AUROC) -1, loc=np.mean(cum_AUROC), scale=st.sem(cum_AUROC))\n",
    "ci_prec = st.t.interval(0.95, len(cum_prec) -1, loc=np.mean(cum_prec), scale=st.sem(cum_prec))\n",
    "\n",
    "print('accuracy: {:.2f} Â± {:.2f}'.format(np.mean(cum_acc) * 100, abs(np.mean(cum_acc) - ci_mean[0]) * 100))\n",
    "print('recall: {:.2f} Â± {:.2f}'.format(np.mean(cum_recall) * 100, abs(np.mean(cum_recall) - ci_recall[0]) * 100))\n",
    "print('f1-score: {:.2f} Â± {:.2f}'.format(np.mean(cum_f1) * 100, abs(np.mean(cum_f1) - ci_f1[0]) * 100))\n",
    "print('precision: {:.2f} Â± {:.2f}'.format(np.mean(cum_prec) * 100, abs(np.mean(cum_prec) - ci_prec[0]) * 100))\n",
    "#print('auc: {:.2f} Â± {:.2f}'.format(np.mean(cum_auc) * 100, abs(np.mean(cum_auc) - ci_auc[0]) * 100))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854e12a-2cce-4921-b2b7-fe797d242178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
