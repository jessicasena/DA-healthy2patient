{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59364e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T19:04:18.793752Z",
     "start_time": "2022-12-13T19:04:18.706052Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "\n",
    "# create a map between the subject_deiden_id and the patient id\n",
    "patient_map = {}\n",
    "patient_enrollment = pd.read_excel('/data/daily_data/patient_id_mapping.xlsx')\n",
    "\n",
    "for row in patient_enrollment.itertuples():\n",
    "    patient_map[row.subject_deiden_id] = row.patient_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa1ba4",
   "metadata": {},
   "source": [
    "# Medication information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee3dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (29,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (17,29,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (17,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (12,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (12,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/xpython_12635/935897569.py:7: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         med_generic_name taken_dates patient_id\n",
      "0  hydromorphone hcl-nacl  2021-11-19       P069\n",
      "1  hydromorphone hcl-nacl  2021-11-19       P069\n",
      "2  hydromorphone hcl-nacl  2021-11-19       P069\n",
      "3  hydromorphone hcl-nacl  2021-11-19       P069\n",
      "4  hydromorphone hcl-nacl  2021-11-19       P069\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('/data/daily_data/*/meds*.csv',\n",
    "                       recursive = True)\n",
    "meds = []\n",
    "taken_dates = []\n",
    "patient = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    med_info = np.char.lower(df[\"med_generic_name\"].to_numpy(dtype=str))\n",
    "    date = df[\"taken_datetime\"].to_numpy()\n",
    "    patient_id = df[\"patient_deiden_id\"].to_numpy()\n",
    "    for m, d, p in zip(med_info, date, patient_id):\n",
    "        if not pd.isna(d):\n",
    "            try:\n",
    "                timestamp = datetime.strptime(d, '%Y-%m-%d')\n",
    "            except Exception as e:\n",
    "                timestamp = datetime.strptime(d, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "            try:\n",
    "                patient.append(patient_map[p])\n",
    "                meds.append(m)\n",
    "                taken_dates.append(timestamp)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "meds = np.asarray(meds)[:, np.newaxis]\n",
    "taken_dates = np.asarray(taken_dates)[:, np.newaxis]\n",
    "patient = np.asarray(patient)[:, np.newaxis]\n",
    "\n",
    "\n",
    "array = np.concatenate([meds, taken_dates, patient], axis=1)\n",
    "df_meds = pd.DataFrame(array, columns=[\"med_generic_name\", \"taken_dates\", \"patient_id\"])\n",
    "df_meds[\"taken_dates\"] = pd.to_datetime(df_meds[\"taken_dates\"])\n",
    "print(df_meds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc85ab",
   "metadata": {},
   "source": [
    "# Pain information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e74bb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def process_dvprs(value):\n",
    "    try:\n",
    "        score = int(value.split(' ')[0])\n",
    "    except:\n",
    "        if value == 'Patient Asleep':\n",
    "            score = -1\n",
    "        elif np.isnan(value):\n",
    "            score = -1\n",
    "        else:\n",
    "            sys.exit('error in dvprs')\n",
    "\n",
    "    return score\n",
    "\n",
    "files = glob.glob('/data/daily_data/*/pain*.csv',\n",
    "                      recursive=True)\n",
    "\n",
    "pain = []\n",
    "timestamps = []\n",
    "patient = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # standardize the timestamp\n",
    "            # timestamp_patient_id\n",
    "            timestamp = datetime.strptime(row['pain_datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "            timestamp = timestamp.strftime('%m-%d-%Y')\n",
    "            patient_id = patient_map[row.patient_deiden_id]\n",
    "            key = f\"{timestamp}_{patient_id}\"\n",
    "            if row.measurement_name == \"pain_uf_dvprs\":\n",
    "                try:\n",
    "                    score = process_dvprs(row.measurement_value)\n",
    "                except:\n",
    "                    score = -1\n",
    "\n",
    "                pain.append(score)\n",
    "                patient.append(patient_id)\n",
    "                timestamps.append(timestamp)\n",
    "        except KeyError as e:\n",
    "            #print(e)\n",
    "            pass\n",
    "\n",
    "pain = np.asarray(pain)[:, np.newaxis]\n",
    "timestamps = np.asarray(timestamps)[:, np.newaxis]\n",
    "patient = np.asarray(patient)[:, np.newaxis]\n",
    "        \n",
    "array = np.concatenate([pain, timestamps, patient], axis=1)\n",
    "df_pain_scores = pd.DataFrame(array, columns=[\"pain_score\", \"datetime\", \"patient_id\"])\n",
    "df_pain_scores[\"datetime\"] = pd.to_datetime(df_pain_scores[\"datetime\"])\n",
    "\n",
    "print(df_pain_scores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891cc086",
   "metadata": {},
   "source": [
    "# Accelerometer information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a449dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T19:04:22.517253Z",
     "start_time": "2022-12-13T19:04:22.490941Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reduce_sampling_rate(data, df_timestamps, reduce_rate):\n",
    "    data_ts = df_timestamps\n",
    "    if reduce_rate != 0:\n",
    "        number_samp = data.shape[0]\n",
    "        samples_slct = list(range(0, number_samp, int(reduce_rate)))\n",
    "        new_data = data[samples_slct]\n",
    "        data_ts = data_ts[samples_slct]\n",
    "        return new_data, data_ts\n",
    "    else:\n",
    "        return data, df_timestamps\n",
    "\n",
    "\n",
    "def read_acc_file_pain_adapt(file_name):\n",
    "    df_acc = pd.read_csv(file_name)\n",
    "    timestamp_col = None\n",
    "    for col in df_acc.columns:\n",
    "        if \"timestamp\" in col.lower():\n",
    "            timestamp_col = col\n",
    "        if \"timestamp\" not in col.lower() and \"accel\" not in col.lower():\n",
    "            df_acc.drop(col, inplace=True, axis=1)\n",
    "        if \"emg\" in col.lower():\n",
    "            raise Exception(\"EMG data found in accelerometer file\")\n",
    "    if timestamp_col and len(df_acc) >= 4:\n",
    "        # in case there is more than one accelerometer, drop the others and keep the first one\n",
    "        columns_to_keep = df_acc.columns[:4].to_numpy()\n",
    "        diff = set(df_acc.columns.to_numpy()).difference(columns_to_keep)\n",
    "        for col in diff:\n",
    "            df_acc.drop(columns=[col], inplace=True)\n",
    "\n",
    "        # curation already converted the timestamp to EST, so we dont need to convert it again\n",
    "        # I had to convert timestamps to pandas due to cudf not supporting milliseconds\n",
    "        # -  that is needed to calculate the frequency of the sensor\n",
    "        # pain and adapt are in EST time zone. But the function bellow convert it to GMT by default\n",
    "        #timestamps = df_acc[timestamp_col].to_numpy(dtype=\"datetime64[ns]\")\n",
    "        #return timestamps, df_acc.drop(columns=[timestamp_col]).to_cupy()\n",
    "        df_acc[timestamp_col] =  pd.to_datetime(df_acc[timestamp_col])\n",
    "        return df_acc\n",
    "    else:\n",
    "        #debug\n",
    "        if not timestamp_col:\n",
    "            print(\"File {}, message: No timestamp \", file_name)\n",
    "        if len(df_acc) <= 4:\n",
    "            print(\"File {}, message: Not enough columns \", file_name)\n",
    "        if len(df_acc) == 0:\n",
    "            print(\"File {}, message: Empty file \", file_name)\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_acc_file_intelligenticu(file_name):\n",
    "    df_acc = cudf.read_csv(file_name, header=10)\n",
    "    if \"Timestamp\" not in df_acc.columns[0]:\n",
    "        print(\"File {} has no timestamp column\".format(file_name))\n",
    "        return None\n",
    "    # we are supposing Intelligent ICU is already on GMT timezone, so no need to convert it\n",
    "    timestamps = cudf.Series(df_acc[\"Timestamp\"], dtype=\"datetime64[ms]\").to_numpy()\n",
    "    return timestamps, df_acc.drop(columns=[\"Timestamp\"]).to_cupy()\n",
    "\n",
    "def get_accs_files(dir_dataset, dataset_name):\n",
    "        accs = []\n",
    "        patients = {}\n",
    "        for root, dirs, files in os.walk(dir_dataset):\n",
    "            for file in files:\n",
    "                ends_string = \"RAW.csv\" if dataset_name == 'intelligent_icu' else \"SD.csv\"\n",
    "                if file.endswith(ends_string):\n",
    "                    if dataset_name == \"intelligent_icu\":\n",
    "                        patient = root.split('/')[5].split(\"_\")[1]\n",
    "                    else:\n",
    "                        patient = root.split('/')[5]\n",
    "                    acc_csv = os.path.join(root, file)\n",
    "                    if patient not in patients:\n",
    "                        patients[patient] = False\n",
    "                    # just get csv files from Accelerometer directories\n",
    "                    if dataset_name == \"intelligent_icu\":\n",
    "                        path = f'{dir_dataset}*/Accelerometer/*'\n",
    "                    else:\n",
    "                        path = f'{dir_dataset}*/*_Accel/Curated_file/*'\n",
    "\n",
    "                    if fnmatch.fnmatch(root, path):\n",
    "                        if 'wrist' in file.lower() or 'arm' in file.lower() or 'emg' in file.lower():\n",
    "                        #if 'wrist' in file.lower() or 'arm' in file.lower():\n",
    "                            if 'emg' not in file.lower():\n",
    "                                patients[patient] = True\n",
    "                                if acc_csv not in accs:\n",
    "                                    accs.append(acc_csv)\n",
    "\n",
    "        for pat, acc_flag in patients.items():\n",
    "            if not acc_flag:\n",
    "                print(\"Patient {}, message: no accelerometer data in directory\", pat)\n",
    "\n",
    "        return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736143f5",
   "metadata": {},
   "source": [
    "### Pain project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ccb8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient {}, message: no accelerometer data in directory P001\n",
      "Patient {}, message: no accelerometer data in directory P060\n",
      "Patient {}, message: no accelerometer data in directory P030\n",
      "Patient {}, message: no accelerometer data in directory P008\n",
      "Patient {}, message: no accelerometer data in directory P035\n",
      "Patient {}, message: no accelerometer data in directory P061\n",
      "Patient {}, message: no accelerometer data in directory P022\n",
      "Patient {}, message: no accelerometer data in directory P069\n",
      "Patient {}, message: no accelerometer data in directory P056\n",
      "Patient {}, message: no accelerometer data in directory P040\n",
      "Patient {}, message: no accelerometer data in directory P071\n",
      "Patient {}, message: no accelerometer data in directory P020\n",
      "Patient {}, message: no accelerometer data in directory P045\n",
      "Patient {}, message: no accelerometer data in directory P026\n",
      "Patient {}, message: no accelerometer data in directory P066\n",
      "Patient {}, message: no accelerometer data in directory P002\n",
      "Patient {}, message: no accelerometer data in directory P011\n",
      "Patient {}, message: no accelerometer data in directory P018\n",
      "\n",
      "Keeping: /home/jsenadesouza/DA-healthy2patient/354_Sensor_data/P013/P013_Accel/Curated_file/2021-07-28_08.59.02_P013_arm3_SD_Session1/P013_arm3_Session1_P013_arm3_Calibrated_SD.csv\n"
     ]
    },
    {
     "ename": "<class 'TypeError'>",
     "evalue": "'>' not supported between instances of 'str' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(acc_sequence) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     22\u001B[0m     daily_acc\u001B[38;5;241m.\u001B[39mappend(df[mask])\n\u001B[0;32m---> 23\u001B[0m     pain_mask \u001B[38;5;241m=\u001B[39m (df_pain_scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatetime\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m day) \u001B[38;5;241m&\u001B[39m (df_pain_scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatetime\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m<\u001B[39m day\u001B[38;5;241m+\u001B[39mpd\u001B[38;5;241m.\u001B[39mTimedelta(days\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     24\u001B[0m     pain_scores \u001B[38;5;241m=\u001B[39m df_pain_scores[pain_mask]\n\u001B[1;32m     26\u001B[0m     med_mask \u001B[38;5;241m=\u001B[39m (df_meds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtaken_date\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m day) \u001B[38;5;241m&\u001B[39m (df_meds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtaken_date\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m<\u001B[39m day\u001B[38;5;241m+\u001B[39mpd\u001B[38;5;241m.\u001B[39mTimedelta(days\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/.conda/envs/jessica/lib/python3.9/site-packages/pandas/core/ops/common.py:72\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     70\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/jessica/lib/python3.9/site-packages/pandas/core/arraylike.py:59\u001B[0m, in \u001B[0;36mOpsMixin.__gt__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__gt__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__gt__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cmp_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgt\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/jessica/lib/python3.9/site-packages/pandas/core/series.py:6246\u001B[0m, in \u001B[0;36mSeries._cmp_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   6243\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m extract_array(other, extract_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   6245\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 6246\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomparison_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6248\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(res_values, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[0;32m~/.conda/envs/jessica/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:287\u001B[0m, in \u001B[0;36mcomparison_op\u001B[0;34m(left, right, op)\u001B[0m\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_object_dtype(lvalues\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rvalues, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 287\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43mcomp_method_OBJECT_ARRAY\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    290\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/.conda/envs/jessica/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:75\u001B[0m, in \u001B[0;36mcomp_method_OBJECT_ARRAY\u001B[0;34m(op, x, y)\u001B[0m\n\u001B[1;32m     73\u001B[0m     result \u001B[38;5;241m=\u001B[39m libops\u001B[38;5;241m.\u001B[39mvec_compare(x\u001B[38;5;241m.\u001B[39mravel(), y\u001B[38;5;241m.\u001B[39mravel(), op)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 75\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mlibops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscalar_compare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mreshape(x\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m~/.conda/envs/jessica/lib/python3.9/site-packages/pandas/_libs/ops.pyx:107\u001B[0m, in \u001B[0;36mpandas._libs.ops.scalar_compare\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: '>' not supported between instances of 'str' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "dir_dataset = \"/home/jsenadesouza/DA-healthy2patient/354_Sensor_data/\"\n",
    "accs_files = get_accs_files(dir_dataset, \"pain\")\n",
    "\n",
    "#for file in tqdm(accs_files):\n",
    "file = \"/home/jsenadesouza/DA-healthy2patient/354_Sensor_data/P013/P013_Accel/Curated_file/2021-07-28_08.59.02_P013_arm3_SD_Session1/P013_arm3_Session1_P013_arm3_Calibrated_SD.csv\"\n",
    "samples = []\n",
    "#try:\n",
    "if 'wrist' not in file and 'arm' not in file:\n",
    "    print(f\"\\nDiscarding: {file}\")\n",
    "else:\n",
    "    print(f'\\nKeeping: {file}')\n",
    "    df = read_acc_file_pain_adapt(file)\n",
    "    patient_id = file.split('/')[5]\n",
    "    init_ts = df[df.columns[0]].min()\n",
    "    last_ts = df[df.columns[0]].max()\n",
    "    date_list = pd.date_range(start=init_ts, end=last_ts, inclusive=\"both\", normalize=True)\n",
    "    daily_acc = []\n",
    "    for day in date_list:\n",
    "        mask = (df[df.columns[0]] > day) & (df[df.columns[0]] < day+pd.Timedelta(days=1))\n",
    "        acc_sequence = df[mask]\n",
    "        if len(acc_sequence) > 0:\n",
    "            daily_acc.append(df[mask])\n",
    "            pain_mask = (df_pain_scores[\"datetime\"] > day) & (df_pain_scores[\"datetime\"] < day+pd.Timedelta(days=1))\n",
    "            pain_scores = df_pain_scores[pain_mask]\n",
    "            \n",
    "            med_mask = (df_meds[\"taken_date\"] > day) & (df_meds[\"taken_date\"] < day+pd.Timedelta(days=1))\n",
    "            med_list = df_meds[med_mask]\n",
    "            \n",
    "            if len(pain_scores) >0 and len(med_list) > 0:\n",
    "                sample = {\"patient_id\": patient_id, \n",
    "                          \"pain_scores\": pain_scores, \n",
    "                          \"meds\": med_list, \n",
    "                          \"acc\":acc_sequence}\n",
    "                samples.append(sample)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547fc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "um_acc_raw = pd.read_csv(\"/data/datasets/ICU_Data/354_Sensor_Data/P057/Accel/2021-11-05_09.12.40_P057_arm3_SD_Session1/P057_arm3_Session1_P057_arm3_Calibrated_SD.csv\", header=2, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a260cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ms</th>\n      <th>m/(s^2)</th>\n      <th>m/(s^2).1</th>\n      <th>m/(s^2).2</th>\n      <th>m/(s^2).3</th>\n      <th>m/(s^2).4</th>\n      <th>m/(s^2).5</th>\n      <th>deg/s</th>\n      <th>deg/s.1</th>\n      <th>deg/s.2</th>\n      <th>Unnamed: 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.636119e+12</td>\n      <td>14.130435</td>\n      <td>8.782609</td>\n      <td>13.293478</td>\n      <td>-3.664871</td>\n      <td>6.420108</td>\n      <td>7.444644</td>\n      <td>48.320611</td>\n      <td>-53.740458</td>\n      <td>42.763359</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.636119e+12</td>\n      <td>12.358696</td>\n      <td>12.402174</td>\n      <td>8.510870</td>\n      <td>-3.222023</td>\n      <td>5.172950</td>\n      <td>6.920407</td>\n      <td>30.931298</td>\n      <td>-59.145038</td>\n      <td>36.702290</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.636119e+12</td>\n      <td>11.663043</td>\n      <td>12.206522</td>\n      <td>8.695652</td>\n      <td>-4.337522</td>\n      <td>5.247157</td>\n      <td>7.265111</td>\n      <td>18.671756</td>\n      <td>-71.816794</td>\n      <td>77.725191</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.636119e+12</td>\n      <td>12.010870</td>\n      <td>11.315217</td>\n      <td>7.793478</td>\n      <td>-3.669659</td>\n      <td>4.689408</td>\n      <td>5.998803</td>\n      <td>-0.305344</td>\n      <td>-67.389313</td>\n      <td>110.793893</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.636119e+12</td>\n      <td>9.934783</td>\n      <td>16.119565</td>\n      <td>8.000000</td>\n      <td>-5.484141</td>\n      <td>7.425494</td>\n      <td>6.408139</td>\n      <td>-18.030534</td>\n      <td>-86.824427</td>\n      <td>150.045802</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             ms    m/(s^2)  m/(s^2).1  m/(s^2).2  m/(s^2).3  m/(s^2).4  \\\n0  1.636119e+12  14.130435   8.782609  13.293478  -3.664871   6.420108   \n1  1.636119e+12  12.358696  12.402174   8.510870  -3.222023   5.172950   \n2  1.636119e+12  11.663043  12.206522   8.695652  -4.337522   5.247157   \n3  1.636119e+12  12.010870  11.315217   7.793478  -3.669659   4.689408   \n4  1.636119e+12   9.934783  16.119565   8.000000  -5.484141   7.425494   \n\n   m/(s^2).5      deg/s    deg/s.1     deg/s.2  Unnamed: 10  \n0   7.444644  48.320611 -53.740458   42.763359          NaN  \n1   6.920407  30.931298 -59.145038   36.702290          NaN  \n2   7.265111  18.671756 -71.816794   77.725191          NaN  \n3   5.998803  -0.305344 -67.389313  110.793893          NaN  \n4   6.408139 -18.030534 -86.824427  150.045802          NaN  "
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "um_acc_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a95f150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}